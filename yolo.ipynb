{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SmRtlWmD3msd",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Bovine Face Identifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VZ2IVXtM3pMz",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PtiJ-wPWFdt-",
    "outputId": "bd2ab1b5-9a97-4b88-b5c1-dab68cef2031",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Mount GDrive\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 888
    },
    "id": "eRVfawUMEsDO",
    "outputId": "1b6a4059-904e-4813-e1d8-6f1f464aecf7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Install and log into Weights & Biases for logging\n",
    "# import wandb\n",
    "# wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "WjlimVKkEgqa",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6c94018b-1e66-47e9-e9cd-9202a67e784a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov5'...\r\n",
      "remote: Enumerating objects: 12422, done.\u001B[K\r\n",
      "remote: Counting objects: 100% (22/22), done.\u001B[K\r\n",
      "remote: Compressing objects: 100% (19/19), done.\u001B[K\r\n",
      "remote: Total 12422 (delta 10), reused 4 (delta 3), pack-reused 12400\u001B[Kbjects:  26% (3230/12422), 1.95 MiB | 1.92 MiB/sReceiving objects:  28% (3479/12422), 1.95 MiB | 1.92 MiB/sReceiving objects:  30% (3727/12422), 1.95 MiB | 1.92 MiB/sReceiving objects:  32% (3976/12422), 2.95 MiB | 1.94 MiB/sReceiving objects:  35% (4348/12422), 2.95 MiB | 1.94 MiB/sReceiving objects:  37% (4597/12422), 2.95 MiB | 1.94 MiB/sReceiving objects:  38% (4834/12422), 2.95 MiB | 1.94 MiB/sReceiving objects:  40% (4969/12422), 3.99 MiB | 1.97 MiB/sReceiving objects:  42% (5218/12422), 3.99 MiB | 1.97 MiB/sReceiving objects:  44% (5466/12422), 3.99 MiB | 1.97 MiB/sReceiving objects:  46% (5715/12422), 3.99 MiB | 1.97 MiB/sReceiving objects:  48% (5963/12422), 3.99 MiB | 1.97 MiB/sReceiving objects:  50% (6211/12422), 3.99 MiB | 1.97 MiB/sReceiving objects:  52% (6460/12422), 5.00 MiB | 1.96 MiB/sReceiving objects:  54% (6763/12422), 5.82 MiB | 1.91 MiB/sReceiving objects:  55% (6833/12422), 7.51 MiB | 1.61 MiB/sReceiving objects:  58% (7205/12422), 7.51 MiB | 1.61 MiB/sReceiving objects:  60% (7454/12422), 7.51 MiB | 1.61 MiB/sReceiving objects:  61% (7578/12422), 8.29 MiB | 1.62 MiB/sReceiving objects:  63% (7826/12422), 8.29 MiB | 1.62 MiB/sReceiving objects:  65% (8075/12422), 8.29 MiB | 1.62 MiB/sReceiving objects:  67% (8323/12422), 9.10 MiB | 1.54 MiB/sReceiving objects:  70% (8696/12422), 9.10 MiB | 1.54 MiB/sReceiving objects:  74% (9193/12422), 9.10 MiB | 1.54 MiB/sReceiving objects:  76% (9441/12422), 9.10 MiB | 1.54 MiB/sReceiving objects:  79% (9814/12422), 10.04 MiB | 1.52 MiB/sReceiving objects:  81% (10062/12422), 10.04 MiB | 1.52 MiB/sReceiving objects:  83% (10311/12422), 10.04 MiB | 1.52 MiB/sReceiving objects:  85% (10559/12422), 10.04 MiB | 1.52 MiB/sReceiving objects:  88% (10932/12422), 10.04 MiB | 1.52 MiB/sReceiving objects:  90% (11180/12422), 11.19 MiB | 1.55 MiB/sReceiving objects:  93% (11553/12422), 11.19 MiB | 1.55 MiB/sReceiving objects:  94% (11687/12422), 12.24 MiB | 1.56 MiB/sReceiving objects:  98% (12174/12422), 12.24 MiB | 1.56 MiB/s\r\n",
      "Receiving objects: 100% (12422/12422), 12.42 MiB | 1.71 MiB/s, done.\r\n",
      "Resolving deltas: 100% (8510/8510), done.\r\n",
      "/Users/adam/Git/agricam/yolov5/yolov5\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Setup complete. Using torch 1.12.0 (CPU)\n"
     ]
    }
   ],
   "source": [
    "# clone YOLOv5 & install dependencies\n",
    "!git clone https://github.com/ultralytics/yolov5 # clone repo\n",
    "%cd yolov5\n",
    "%pip install -qr requirements.txt # install dependencies\n",
    "\n",
    "import torch\n",
    "from IPython.display import Image, clear_output  # to display images\n",
    "\n",
    "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izgiTGbc3XtL",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m6bF_Q8K-tCS",
    "outputId": "2f758639-8bb9-4ecd-d0df-1e2815ea3fad",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mweights=yolov5s.pt, cfg=, data=dataset/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=300, batch_size=128, imgsz=224, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=cowface, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\r\n",
      "\u001B[34m\u001B[1mgithub: \u001B[0mup to date with https://github.com/ultralytics/yolov5 âœ…\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/Users/adam/Git/agricam/yolov5/yolov5/train.py\", line 625, in <module>\r\n",
      "    main(opt)\r\n",
      "  File \"/Users/adam/Git/agricam/yolov5/yolov5/train.py\", line 495, in main\r\n",
      "    check_file(opt.data), check_yaml(opt.cfg), check_yaml(opt.hyp), str(opt.weights), str(opt.project)  # checks\r\n",
      "  File \"/Users/adam/Git/agricam/yolov5/yolov5/utils/general.py\", line 456, in check_file\r\n",
      "    assert len(files), f'File not found: {file}'  # assert file was found\r\n",
      "AssertionError: File not found: dataset/data.yaml\r\n"
     ]
    }
   ],
   "source": [
    "# Train a new model on the dataset\n",
    "!python train.py --project cowface --img 224 --batch 128 --epochs 300 --data 'dataset/data.yaml' --weights yolov5s.pt --cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xYWnsGgF3das",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Detection & Localisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "p-BXt7gXsnZT",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# The pretrained model to use\n",
    "model = 'n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CF9nGL49YzkS",
    "outputId": "4396c4c7-bbe1-4182-dc98-8d6aec15b886",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/adam/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2022-7-27 Python-3.9.12 torch-1.12.0 CPU\n",
      "\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "[Errno 2] No such file or directory: 'best.pt'. Cache may be out of date, try `force_reload=True` or see https://github.com/ultralytics/yolov5/issues/36 for help.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[0;32m~/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py:46\u001B[0m, in \u001B[0;36m_create\u001B[0;34m(name, pretrained, channels, classes, autoshape, verbose, device)\u001B[0m\n\u001B[1;32m     45\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m pretrained \u001B[38;5;129;01mand\u001B[39;00m channels \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m3\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m classes \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m80\u001B[39m:\n\u001B[0;32m---> 46\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[43mDetectMultiBackend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfuse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mautoshape\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# download/load FP32 model\u001B[39;00m\n\u001B[1;32m     47\u001B[0m     \u001B[38;5;66;03m# model = models.experimental.attempt_load(path, map_location=device)  # download/load FP32 model\u001B[39;00m\n\u001B[1;32m     48\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:334\u001B[0m, in \u001B[0;36mDetectMultiBackend.__init__\u001B[0;34m(self, weights, device, dnn, data, fp16, fuse)\u001B[0m\n\u001B[1;32m    333\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m pt:  \u001B[38;5;66;03m# PyTorch\u001B[39;00m\n\u001B[0;32m--> 334\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[43mattempt_load\u001B[49m\u001B[43m(\u001B[49m\u001B[43mweights\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mweights\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mw\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minplace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfuse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfuse\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    335\u001B[0m     stride \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmax\u001B[39m(\u001B[38;5;28mint\u001B[39m(model\u001B[38;5;241m.\u001B[39mstride\u001B[38;5;241m.\u001B[39mmax()), \u001B[38;5;241m32\u001B[39m)  \u001B[38;5;66;03m# model stride\u001B[39;00m\n",
      "File \u001B[0;32m~/.cache/torch/hub/ultralytics_yolov5_master/models/experimental.py:80\u001B[0m, in \u001B[0;36mattempt_load\u001B[0;34m(weights, device, inplace, fuse)\u001B[0m\n\u001B[1;32m     79\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m w \u001B[38;5;129;01min\u001B[39;00m weights \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(weights, \u001B[38;5;28mlist\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m [weights]:\n\u001B[0;32m---> 80\u001B[0m     ckpt \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mattempt_download\u001B[49m\u001B[43m(\u001B[49m\u001B[43mw\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmap_location\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcpu\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# load\u001B[39;00m\n\u001B[1;32m     81\u001B[0m     ckpt \u001B[38;5;241m=\u001B[39m (ckpt\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mema\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m ckpt[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m'\u001B[39m])\u001B[38;5;241m.\u001B[39mto(device)\u001B[38;5;241m.\u001B[39mfloat()  \u001B[38;5;66;03m# FP32 model\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/pam08/lib/python3.9/site-packages/torch/serialization.py:699\u001B[0m, in \u001B[0;36mload\u001B[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001B[0m\n\u001B[1;32m    697\u001B[0m     pickle_load_args[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m--> 699\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43m_open_file_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m opened_file:\n\u001B[1;32m    700\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_zipfile(opened_file):\n\u001B[1;32m    701\u001B[0m         \u001B[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001B[39;00m\n\u001B[1;32m    702\u001B[0m         \u001B[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001B[39;00m\n\u001B[1;32m    703\u001B[0m         \u001B[38;5;66;03m# reset back to the original position.\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/pam08/lib/python3.9/site-packages/torch/serialization.py:230\u001B[0m, in \u001B[0;36m_open_file_like\u001B[0;34m(name_or_buffer, mode)\u001B[0m\n\u001B[1;32m    229\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _is_path(name_or_buffer):\n\u001B[0;32m--> 230\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_open_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/anaconda3/envs/pam08/lib/python3.9/site-packages/torch/serialization.py:211\u001B[0m, in \u001B[0;36m_open_file.__init__\u001B[0;34m(self, name, mode)\u001B[0m\n\u001B[1;32m    210\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name, mode):\n\u001B[0;32m--> 211\u001B[0m     \u001B[38;5;28msuper\u001B[39m(_open_file, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'best.pt'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mException\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [14]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      3\u001B[0m   model \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mhub\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124multralytics/yolov5\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124myolov5s\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m      5\u001B[0m   \u001B[38;5;66;03m# Load custom model\u001B[39;00m\n\u001B[1;32m      6\u001B[0m   \u001B[38;5;66;03m# shutil.copy(f'/content/drive/MyDrive/Cowface/models/run{model}/best.pt', '/content/')\u001B[39;00m\n\u001B[0;32m----> 7\u001B[0m   model \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhub\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43multralytics/yolov5\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcustom\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbest.pt\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/pam08/lib/python3.9/site-packages/torch/hub.py:540\u001B[0m, in \u001B[0;36mload\u001B[0;34m(repo_or_dir, model, source, trust_repo, force_reload, verbose, skip_validation, *args, **kwargs)\u001B[0m\n\u001B[1;32m    536\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m source \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgithub\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    537\u001B[0m     repo_or_dir \u001B[38;5;241m=\u001B[39m _get_cache_or_reload(repo_or_dir, force_reload, trust_repo, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mload\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    538\u001B[0m                                        verbose\u001B[38;5;241m=\u001B[39mverbose, skip_validation\u001B[38;5;241m=\u001B[39mskip_validation)\n\u001B[0;32m--> 540\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43m_load_local\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrepo_or_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    541\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "File \u001B[0;32m~/anaconda3/envs/pam08/lib/python3.9/site-packages/torch/hub.py:569\u001B[0m, in \u001B[0;36m_load_local\u001B[0;34m(hubconf_dir, model, *args, **kwargs)\u001B[0m\n\u001B[1;32m    566\u001B[0m hub_module \u001B[38;5;241m=\u001B[39m _import_module(MODULE_HUBCONF, hubconf_path)\n\u001B[1;32m    568\u001B[0m entry \u001B[38;5;241m=\u001B[39m _load_entry_from_hubconf(hub_module, model)\n\u001B[0;32m--> 569\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mentry\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    571\u001B[0m sys\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mremove(hubconf_dir)\n\u001B[1;32m    573\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "File \u001B[0;32m~/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py:72\u001B[0m, in \u001B[0;36mcustom\u001B[0;34m(path, autoshape, _verbose, device)\u001B[0m\n\u001B[1;32m     70\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcustom\u001B[39m(path\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpath/to/model.pt\u001B[39m\u001B[38;5;124m'\u001B[39m, autoshape\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, _verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, device\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m     71\u001B[0m     \u001B[38;5;66;03m# YOLOv5 custom or local model\u001B[39;00m\n\u001B[0;32m---> 72\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_create\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mautoshape\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mautoshape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_verbose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py:67\u001B[0m, in \u001B[0;36m_create\u001B[0;34m(name, pretrained, channels, classes, autoshape, verbose, device)\u001B[0m\n\u001B[1;32m     65\u001B[0m help_url \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttps://github.com/ultralytics/yolov5/issues/36\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m     66\u001B[0m s \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. Cache may be out of date, try `force_reload=True` or see \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhelp_url\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m for help.\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m---> 67\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(s) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "\u001B[0;31mException\u001B[0m: [Errno 2] No such file or directory: 'best.pt'. Cache may be out of date, try `force_reload=True` or see https://github.com/ultralytics/yolov5/issues/36 for help."
     ]
    }
   ],
   "source": [
    "if model == 's':\n",
    "  # Load YOLOv5s\n",
    "  model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
    "else:\n",
    "  # Load custom model\n",
    "  # shutil.copy(f'/content/drive/MyDrive/Cowface/models/run{model}/best.pt', '/content/')\n",
    "  model = torch.hub.load('ultralytics/yolov5', 'custom', path='best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lz-nSCStF52m",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch._C import StringType\n",
    "from IPython.display import display\n",
    "\n",
    "'''\n",
    "Run inference on, and return a cell count for, the given image\n",
    "'''\n",
    "def detect(img: str):\n",
    "  # Run inference on the images\n",
    "  results = model(f'/content/drive/MyDrive/Cowface/dataset/images/{img}.jpg')\n",
    "\n",
    "  # Iterate through the DataFrames and sum their lengths for a count of cells in the image\n",
    "  df = results.pandas().xyxy\n",
    "\n",
    "  # Display the first image in the results\n",
    "  # print(len(results.imgs))\n",
    "  results.render()\n",
    "  display(results.imgs[0])\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9bAUjtqU6PIZ",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484
    },
    "outputId": "800fae05-9f11-4ecb-bfcd-99741dbc4c8e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df1 = detect('test_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FlyWGYSijNLg",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484
    },
    "outputId": "944a9c07-8615-4031-9016-a80579eeebec",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df2 = detect('test_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3-WgLyBGjNnY",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 674
    },
    "outputId": "53d40e7c-5778-46d1-eba9-59ce3664bbb5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df3 = detect('test_3')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Cowface",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}